---
title: "Interpretability via Symbolic Distillation"
date: 2023-09-22
permalink: /posts/2023/09/sym-dist/
tags:
  - posts
---

Intriguing approach to interpretability in NNs, particulary in the scientific domain. This paper argues that science has a fantastic built in
modeling language, aka mathematics which we leverage to come up with realtively simple (in relation to neural paradigms), closed form expressions that
describe physical phenomena, sufficiently accurately. These formulae have many benefits. They are compact and they generalize well. But perhaps most importantly, they explicitely spell out their interpretations, something that is critically missing from neurally learned functions.

But discovering such symbolic expressions is hard. Traditionally, symbolic regression has been the tool of choice to tackle these problems. Contemporary methods made use of genetic algorithms to mutate expressions to explore more of the symbolic expression space. But such methods usually suffer exponential explosions as the number of symbols increases and hence quickly turn intractable for high dimensional data

<br>
<img width="860" alt="image" src="/sym_reg.png">
Exploring the expression space with genetic algorithms

<br>

The authors attempt to improve on this by leveraging Graph Neural Nets (GNNs). They make the claim that GNNs have strong and well motivated inductive biases and this aligns them well with the problem statement. I am not super familiar with GNNs but it looks like they distill the latent representations learnt by the network into symbolic expressions, which they can then combine to form a closed form expression. One important detail here is that they are still using traditional symbolic regression to arrive at the final expression but they do so in 'part by part' manner. To make the symbolic regression more efficient they encourage sparsity in the latent representations (using L1 and KL penalty terms).

In essence, they use the sparsity of the latent representations and internally seperable structure of the GNN to learn many distinct, internal functions. Then, performing symbolic regression on these internal functions and then finally replace them with a closed form expression in the final model. They claim that this approach was able to recover symbolic expressions of Newton's laws simply from looking at data of a N body particle simulation

[Link](https://www.youtube.com/watch?v=XHBJJ2N-kUc) to the full talk
[Link](https://arxiv.org/pdf/2006.11287.pdf) to the paper
